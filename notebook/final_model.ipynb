{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57986370",
   "metadata": {},
   "source": [
    "## Churn Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7252d46a",
   "metadata": {},
   "source": [
    "### Importing Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3b18a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE  \n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc12e20",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7291b662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>tenure_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  SeniorCitizen  Partner  Dependents  PhoneService  MultipleLines  \\\n",
       "0       0              0        1           0             0              1   \n",
       "1       1              0        0           0             1              0   \n",
       "2       1              0        0           0             1              0   \n",
       "3       1              0        0           0             0              1   \n",
       "4       0              0        0           0             1              0   \n",
       "\n",
       "   InternetService  OnlineSecurity  OnlineBackup  DeviceProtection  \\\n",
       "0                0               0             2                 0   \n",
       "1                0               2             0                 2   \n",
       "2                0               2             2                 0   \n",
       "3                0               2             0                 2   \n",
       "4                1               0             0                 0   \n",
       "\n",
       "   TechSupport  StreamingTV  StreamingMovies  Contract  PaperlessBilling  \\\n",
       "0            0            0                0         0                 1   \n",
       "1            0            0                0         1                 0   \n",
       "2            0            0                0         0                 1   \n",
       "3            2            0                0         1                 0   \n",
       "4            0            0                0         0                 1   \n",
       "\n",
       "   PaymentMethod  MonthlyCharges  TotalCharges  Churn  tenure_group  \n",
       "0              2           29.85         29.85      0             0  \n",
       "1              3           56.95       1889.50      0             2  \n",
       "2              3           53.85        108.15      1             0  \n",
       "3              0           42.30       1840.75      0             3  \n",
       "4              2           70.70        151.65      1             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Final_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446cf44e",
   "metadata": {},
   "source": [
    "## Spliting data into input variable X and Target Variable y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6328e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  df.drop('Churn', axis=1)\n",
    "y = df['Churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c397e592",
   "metadata": {},
   "source": [
    "## Splitting data for train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb3bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3180a331",
   "metadata": {},
   "source": [
    "## Checking Various ML Algho in primary stage to see which is most fitted for our business solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c09e5b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_check(X_train, X_test, y_train, y_test):\n",
    "    pipelines = {\n",
    "    'Random Forest': make_pipeline(StandardScaler(), SimpleImputer(), RandomForestClassifier()),\n",
    "    'SVM': make_pipeline(StandardScaler(), SVC(probability=True)),\n",
    "    'Naive Bayes': make_pipeline(StandardScaler(), GaussianNB()),\n",
    "    'Decision Tree': make_pipeline(StandardScaler(), DecisionTreeClassifier()),\n",
    "    'K-Nearest Neighbors': make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
    "    }\n",
    "\n",
    "    for step, pipeline in pipelines.items():\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"{step} Metrics:\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "        print(f\"F1 Score: {f1}\")\n",
    "        print('*' * 20)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71be7847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Accuracy: 0.7810945273631841\n",
      "Precision: 0.6204379562043796\n",
      "Recall: 0.45454545454545453\n",
      "F1 Score: 0.5246913580246914\n",
      "********************\n",
      "SVM Metrics:\n",
      "Accuracy: 0.7910447761194029\n",
      "Precision: 0.6515151515151515\n",
      "Recall: 0.45989304812834225\n",
      "F1 Score: 0.5391849529780565\n",
      "********************\n",
      "Naive Bayes Metrics:\n",
      "Accuracy: 0.7391613361762616\n",
      "Precision: 0.5065176908752328\n",
      "Recall: 0.7272727272727273\n",
      "F1 Score: 0.5971459934138309\n",
      "********************\n",
      "Decision Tree Metrics:\n",
      "Accuracy: 0.7263681592039801\n",
      "Precision: 0.48405797101449277\n",
      "Recall: 0.446524064171123\n",
      "F1 Score: 0.46453407510431155\n",
      "********************\n",
      "K-Nearest Neighbors Metrics:\n",
      "Accuracy: 0.7356076759061834\n",
      "Precision: 0.5027624309392266\n",
      "Recall: 0.48663101604278075\n",
      "F1 Score: 0.4945652173913044\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "model_check(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0924f961",
   "metadata": {},
   "source": [
    "### From above result we can decide to go with Decision Tree and Random Forest Classifier and check which is best suited for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48b43486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_model_dt_rf(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    model_dt = DecisionTreeClassifier(criterion = \"gini\",\n",
    "                                  max_depth=6, \n",
    "                                  min_samples_leaf=8)\n",
    "\n",
    "    model_dt.fit(X_train,y_train)\n",
    "\n",
    "    y_pred = model_dt.predict(X_test)\n",
    "    print(\"DecisionTreeClassifier Result\")\n",
    "    \n",
    "    print(model_dt.score(X_test,y_test))\n",
    "    print(classification_report(y_test, y_pred, labels=[0,1]))\n",
    "\n",
    "    model_rf = RandomForestClassifier(n_estimators=100,\n",
    "                                      criterion='gini',\n",
    "                                      max_depth=6,\n",
    "                                      min_samples_leaf=8)\n",
    "    \n",
    "    model_rf.fit(X_train, y_train)\n",
    "    y_pred = model_rf.predict(X_test)\n",
    "    \n",
    "    print(\"RandomForestClassifier Result\")\n",
    "    \n",
    "    print(model_rf.score(X_test,y_test))\n",
    "    print(classification_report(y_test, y_pred, labels=[0,1]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c55bdd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier Result\n",
      "0.7633262260127932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84      1033\n",
      "           1       0.55      0.57      0.56       374\n",
      "\n",
      "    accuracy                           0.76      1407\n",
      "   macro avg       0.70      0.70      0.70      1407\n",
      "weighted avg       0.77      0.76      0.76      1407\n",
      "\n",
      "RandomForestClassifier Result\n",
      "0.7889125799573561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86      1033\n",
      "           1       0.65      0.44      0.53       374\n",
      "\n",
      "    accuracy                           0.79      1407\n",
      "   macro avg       0.74      0.68      0.70      1407\n",
      "weighted avg       0.77      0.79      0.77      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre_model_dt_rf(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f510d0",
   "metadata": {},
   "source": [
    "### As you can see that the accuracy is quite low, and as it's an imbalanced dataset, we shouldn't consider Accuracy as our metrics to measure the model, as Accuracy is cursed in imbalanced datasets.\n",
    "\n",
    "### Hence, we need to check recall, precision & f1 score for the minority class, and it's quite evident that the precision, recall & f1 score is too low for Class 1, i.e. churned customers.\n",
    "\n",
    "### Hence, moving ahead to call SMOTEENN (UpSampling + ENN)rom above results we can clearly see that our model predict more accurate foer 0 churn but not working good on 1 classification so we can use SMOTEENN technique to upsampling or downsampling the data to get more accurate result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "784a5992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_model(X,y):\n",
    "    sm = SMOTEENN()\n",
    "    X, y = sm.fit_resample(X,y)\n",
    "    \n",
    "    ## split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=1)\n",
    "    \n",
    "    #using smoteenn technique\n",
    "    print(\"Decision Tree Classifier with SMOTEENN \")\n",
    "    model = DecisionTreeClassifier(criterion = \"gini\",\n",
    "                                   max_depth=6,\n",
    "                                   min_samples_leaf=8)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    model_score = model.score(X_test,y_test)\n",
    "    print('model_score', model_score)\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print('*'*50)\n",
    "    \n",
    "    #using Random forest\n",
    "    print(\"Random Forest Classifier with SMOTEENN \")\n",
    "    model1 = RandomForestClassifier(n_estimators=100,\n",
    "                                  criterion='gini',\n",
    "                                  max_depth=6,\n",
    "                                  min_samples_leaf=8)\n",
    "    model1.fit(X_train,y_train)\n",
    "    y_pred = model1.predict(X_test)\n",
    "    model_score = model.score(X_test,y_test)\n",
    "    print('model_score', model_score)\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print('*'*50)\n",
    "    \n",
    "    with open('Final_model.pkl', 'wb') as model_file:\n",
    "        pickle.dump(model1, model_file)\n",
    "    print('pickle file saved!')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4f46b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier with SMOTEENN \n",
      "model_score 0.9171648163962425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       523\n",
      "           1       0.91      0.95      0.93       648\n",
      "\n",
      "    accuracy                           0.92      1171\n",
      "   macro avg       0.92      0.91      0.92      1171\n",
      "weighted avg       0.92      0.92      0.92      1171\n",
      "\n",
      "**************************************************\n",
      "Random Forest Classifier with SMOTEENN \n",
      "model_score 0.9171648163962425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       523\n",
      "           1       0.92      0.94      0.93       648\n",
      "\n",
      "    accuracy                           0.92      1171\n",
      "   macro avg       0.92      0.92      0.92      1171\n",
      "weighted avg       0.92      0.92      0.92      1171\n",
      "\n",
      "**************************************************\n",
      "pickle file saved!\n"
     ]
    }
   ],
   "source": [
    "final_model(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f736d9",
   "metadata": {},
   "source": [
    "## Doccumentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179bba05",
   "metadata": {},
   "source": [
    "Certainly, I can provide some suggestions based on the performance metrics you've obtained. The choice of the best classifier depends on your specific objectives and the trade-offs you are willing to make.\n",
    "\n",
    "1. **SVM (Support Vector Machine):**\n",
    "   - It has the highest accuracy among the classifiers.\n",
    "   - It has a relatively balanced F1 score, indicating a good trade-off between precision and recall.\n",
    "   - SVM is known for its ability to handle complex decision boundaries.\n",
    "\n",
    "2. **Random Forest:**\n",
    "   - While it has a slightly lower accuracy than SVM, it has the highest precision among the classifiers.\n",
    "   - It's a robust classifier that can handle a variety of data types and feature importance analysis.\n",
    "\n",
    "3. **Naive Bayes:**\n",
    "   - It has the highest recall among the classifiers, suggesting that it's good at identifying positive cases (churn).\n",
    "   - It has a relatively balanced F1 score.\n",
    "\n",
    "4. **K-Nearest Neighbors:**\n",
    "   - It has a balanced accuracy, precision, recall, and F1 score.\n",
    "   - K-Nearest Neighbors can be simple to understand and implement.\n",
    "\n",
    "5. **Decision Tree:**\n",
    "   - While it has the lowest accuracy and F1 score, it may still be a viable choice if interpretability is essential.\n",
    "   - Decision trees are easy to explain and understand, making them valuable in scenarios where interpretability is crucial.\n",
    "\n",
    "our choice should consider the business context and objectives of your telecom churn project. Here are some factors to consider:\n",
    "\n",
    "- **Balancing Precision and Recall:** If minimizing false positives (precision) is more critical to you, go with Random Forest. If it's more important to capture all true positives (recall), consider Naive Bayes.\n",
    "\n",
    "- **Complexity:** SVM and Random Forest are more complex models, while Naive Bayes and K-Nearest Neighbors are simpler to understand and implement.\n",
    "\n",
    "- **Interpretability:** Decision trees are highly interpretable, which can be beneficial in certain situations.\n",
    "\n",
    "- **Performance:** If overall accuracy is the primary goal, SVM performs well. If you need a balance between precision and recall, consider Random Forest or Naive Bayes.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
